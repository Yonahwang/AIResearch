#postgresql
postgre.user =postgres
postgre.password =12345)(*&^%RFVwsx
postgre.address =jdbc:postgresql://10.130.10.22:5432/BDSSA1
postgre.table.name.train =t_history_modelrules
asset.table = T_MONI_DEVICE_IP
find.table = T_SIEM_DEV_FIND

#es
es.nodes = 10.130.10.18
es.port =9200

#hdfs
hdfsUrl=hdfs://10.130.10.62:9000
httpHDFS=/spark/data/http

#spark
#spark.master.url = spark://172.16.10.115:7077
spark.master.url = local
spark.app.name = assetStatics
spark.port.maxRetries = 1000
spark.cores.max = 6
spark.executor.memory = 8g

# ---------------------Yt@AssetStats(changeAsset、outAsset、idleAsset,)-----------------------

#每天凌晨00:30运行一次
run.time=00:30

##---------------changeAsset start----------------------------
#设置资产变化ip发生event种类的阈值 （端口异常、异常流量）
anomaly_event_kinds= 1
##---------------changeAsset end----------------------------

##---------------idleAsset start----------------------------
#设置流量阈值(每5min的字节数1KB=1024）
netflow.threshold=1024
#设置天数的阈值（默认为3day）
idle.day.threshold=3
#闲置资产的flag
idle.flag=5
##---------------idleAsset end----------------------------

##---------------outAsset start----------------------------
#设置outAsset的历史周期（默认为30天）
out.day.threshold= 30
#退网资产的flag
out.flag=3
##---------------outAsset end----------------------------

# ---------------------Yt@AssetStats(changeAsset、outAsset、idleAsset,)-----------------------