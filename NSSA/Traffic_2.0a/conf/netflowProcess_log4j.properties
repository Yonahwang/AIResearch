# Define the root logger with appender file
#log = /home/spark/DataminingServer/logs
#log = F:\\AssetAbnormal\\log
log = ../logs
#定义LOG输出级别
log4j.rootLogger = ERROR,STDOUT,FILE

# 定义文件file appender
log4j.appender.FILE=org.apache.log4j.FileAppender
#log4j.appender.FILE.File=${log}/wrapper.log
log4j.appender.FILE.File=${log}/Yt_allmodel.log
# 定义控制台 STDOUT appender
log4j.appender.STDOUT=org.apache.log4j.ConsoleAppender
log4j.appender.STDOUT.Target=System.out

# 定义日志输出目的地为文件
log4j.appender.FILE.layout=org.apache.log4j.PatternLayout
log4j.appender.FILE.layout.conversionPattern=%d{yyyy-MM-dd HH:mm:ss} %m%n
#定义日志输出目的地为控制台
log4j.appender.STDOUT.layout=org.apache.log4j.PatternLayout
log4j.appender.STDOUT.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %m%n