
###############public##########################
#spark
#spark.master.url =local
spark.master.url = spark://10.130.10.31:7077
spark.app.name =job_one_hour
spark.port.maxRetries =1000
spark.cores.max =12
spark.executor.memory =4G
spark.sql.shuffle.partitions =400
spark.sql.crossJoin.enabled =true
spark.sql.codegen =true
spark.executor.instances = 6

#postgresql
postgre.user =postgres
postgre.password =12345)(*&^%RFVwsx
postgre.address =jdbc:postgresql://10.130.10.9:5432/BDSSA1
postgre.table.name.train =t_history_modelrules
postgre.table.result =thostattacks
asset.table = T_MONI_DEVICE_IP

#es
es.nodes = 10.130.10.51
es.port =9200

#kafka
kafka.nodes =10.130.10.52:9092, 10.130.10.62:9092, 10.130.10.72:9092
kafka.topic1=topic-modelresult
kafka.topic2=topic-hostattacks
kafka.topic3=topic-botnetportrait

#hdfs
hdfs.path =hdfs://10.130.10.41:9000
hdfs.origin.data.path =/usr/hadoop/nta/
hdfs.clean.data.path =/spark/data/
hdfs.netflow.path = /spark/data/netflow
hdfs.dns.path = /spark/data/dns


###############public##########################




###############private##########################

#schedule task
log.path = ../logs/job_one_hour_runtime.log
run.time =00

###################TANGLE DNS Task ################################

##dns模型地址
dnsTaskDet.model = /spark/model/RandomForestModel_DNS/
dnsTask.index = predict
dnsTaskDet.InputFile = /spark/data/dns
###################TANGLE DNS Task ################################


# ----------Yt@detectDGA  Start ---------------------------------------------------------------------
## domain白名单
white.domain.path = /spark/dga_corr_data/white_domain.txt
## 顶级域名获取列表路径
suffix.Path.name = /spark/dga_corr_data/public_suffix_list.dat
## hmm转移概率路径
HmmPro.Path.name = /spark/dga_corr_data/bigramHmmPro.csv
## n-gram在Alexa的排名
NgramRank.Path.name = /spark/dga_corr_data/topAlexaNgramRank.csv
## 获取模型训练路径
model.Path.name = /spark/dga_corr_data/GBTTrainModel

# 设置域名的长度阈值
dns.domain.length = 10
# 设置某个ip在1h内访问dga域名的最小次数
skim.dga.nums = 5
# 设置某个ip在1h内访问dga域名的最小个数
dns.dga.nums = 2

## dgaDomain文件路径
save.dga.path = /home/spark/DataminingServer/sign/dga_domain.txt
# ----------Yt@detectDGA  End-------------------------------------------------------------------------


# ----------Yt@trafficAnomlay   Start---------------------------------------------------------------------
## 训练周期
train.period.day = 7
## 读取允许连续超过最大阈值的次数
baseline.out.number = 6
# ----------Yt@trafficAnomlay   End-------------------------------------------------------------------------



# -------------tyb-----------------
# tyb_share
modelResult=tmodelresult/tmodelresult
#true,false
containsSelect=true
httpHDFS=/spark/data/http
NegativeDataPath=E:/ScalaCode/Algorithm/AlgorithmModel/unwantedcode/negetivedata/
PositiveDataPath=E:/ScalaCode/Algorithm/AlgorithmModel/unwantedcode/positivedata/


# HostAttacks
hostAttacks=thostattacks
postgre.table.name.event = t_siem_event_result
postgre.table.name.bot = tbotnetportrait/tbotnetportrait
postgre.table.name.sample = t_host_attack_sample_collect
postgre.table.name.weight = t_host_attack_weight_rule
scoreline=60
confDelete=false


# MaliciousCode
TrainModelPathMaliciousCode=hdfs://10.130.10.41:9000//spark/model/codeModel/
#predict,train
indexMaliciousCode=predict


# SQLInjectionAttacks
TrainModelPathSQLInjectionAttacks=hdfs://10.130.10.41:9000//spark/model/sqlModel/
#predict,train
indexSQLInjectionAttacks=predict
# -------------tyb-----------------



###############private##########################
