# Machine Learning {PDF} Malware Detection Engine

## Time Range
 - 2018 Q1

## Project Status
 - On Schedule (2018/03/22)

## Research Scientist
 - [Fengjiao Wang](https://github.com/Yonahwang)
 - [Wei Jiang](https://weijiang2009.github.io/)

## OKR
### Objective
- IMPROVE Malware Detection and Classification Engine Research Prototype & Automatically Evading Classifiers Research Prototype

### Key Results（可量化的关键成果）

在 当前PDF检测引擎 基础上，从 速度 & 质量 2方面 改善模型：

 
  2. 2018 Q1 现 PDF分类器 改进：
  
  - 1)（基础）平衡 现有 数据集，使 其总数据集 规模 达 10万 级别 （恶：好 = 15 ：2） -- DONE //-20万 
  
  - 2)（基础）添加 新近的，自己生成的，变异 PDF恶意样本（2017-2018） ~~3 ~~约7000个（级别）
  
  - 3）~~计算 模型 检测率，并 添加样本 到 模型中，形成 模型 自动 生成 -》 分发的 流水线~~
  
  - 4)（中级）添加 动态分析 的特征 个（级别）及补充起内容说明 -- **Delayed** due to multi reasons including time constraint, env set up and the skill level of the people (Will be pushed to Q2)---（0.2-0.3）
  
  - 5)（中级）~~增加 “深度特征” ？个 提取（对 特征 按照深度 进行 排列），并 根据 4大国际 安全论文集，更新 现有 特征集，不再 仅停留于 浅层特征，~~ 最终 目的是 ：**提高模型** 的 **健壮性**（包括有 更新特征，比之前的特征集 获得更好的精度；生成一个有抗逃逸能力的模型）
   
  - 6)（中级）~~加固现在的分类器，使用 **神经网络** 生成 **自动** 对抗的分类器 若干个（？量化，当 准确度 下降到 某一阀值 时，自动训练 分类器）~~drop
  - 7)（高级 - ~~论文~~数据报告写作）新 完成 ~~英文~~中文~~论文~~数据报告 一篇到4月上旬~~信息安全顶级会议~~ ~~提交到Ronald处，并与大家分享~~
 
  - 8)（高级 - 研究方向初步确定）阅读并收集 至少 5份 顶会论文，形成自己独有的研究方向 1个，由此产生技术壁垒基础 -- DONE
  
## Paper DONE reading
 - PlatPal: Detecting Malicious Documents with Platform Diversity ,USENIX2017,Meng Xu and Taesoo Kim
 - (基于动态分析，有大量的领域知识，但此论文并没有直接使用机器学习的方法。对于好样本，在跨平台的运行过程中，行为一致；而对于恶意样本，跨平台行为会不同。如 此恶意软件只在WinXP下的某个版本的PDF Reader下执行)
 - Automatically Evading Classifiers A Case Study on PDF Malware Classifiers, NDSS2016, Weilin Xu et. al.
 - (简单的说，恶意样本在初始阶段被判定为恶意，经过多次的自动演变，最终在保持恶意行为的基础下，逃逸分类器)
 - Hidost a static machine-learning-based detector of malicious files EURASIP2016，Nedim S
 - (重新改变模型，并且对其他的文件具有兼容性（如Flash等），更新的模型的框架)
 - Practical Evasion of a Learning-Based Classifier:A Case Study，SP2014, Nedim ˇ Srndi´c and Pavel Laskov
 - （8种逃逸分类器的情况，假设有一个用了4种特征的分类器，为A（0.1），B（0.1），C（0.9），D（0.1）通过改变特征C就可以）
 - Detection Of Malicious PDF Files Based On Hierarchical Document Structure, NDSS2013, Nedim S and Pavel L
 - （PDF文件结构，提取重要特征，主要针对特征，算法方面很少，机器学习）
 - Helping Johnny to Analyze Malware A Usability-Optimized Decompiler and Malware Analysis User Study, SP2016, K Yakdan et. al.

## Paper in progress
 - Extract Me If You Can: Abusing PDF Parsers in Malware Detectors, NDSS2016
 - When a Tree Falls: Using Diversity in Ensemble Classifiers to Identify Evasion in Malware Detectors, NDSS2016 （比较数学，提取一点有用的信息即可）
 - Malicious PDF Detection using Metadata and structural features, ACSAC 2012
 
#### Roadmap
（Updated on 2018/3/22）
- 1) 针对新提取的特征做可视化的分类效果的展示
- 2）生成新的逃逸样本，约6000（变异了3次）

（Updated on 2018/3/16）
- 1)基于前几篇论文的研究和代码，研究新的分类模型，新的分类模型主要针对分类器的鲁棒性和恶意文件的逃逸，替换掉之前的模型，

（Updated on 2018/3/12）
- 1)研究内容重梳理，并添加2018 Q2的Side Project - 基于机器学习的漏洞检测, NDSS 2018, A Deep Learning-Based System for Vulnerability Detection

（Updated on 2018/3/9）
- 1)阅读 关于恶意文件逃逸问题的平台多样性新视角，并作阅读笔记更新到github上
- 2)使用与搭建多个环境以用于PDF文件解析的工具，以助于挖掘深度特征
- 3)针对于分类器鲁棒性的问题，和算法的调优

（Updated on 2018/2/27）
- 1)平衡正常样本数据集，提取到有效文件的特征文件csv,并使用AI的方式进行分类
- 2)增加动态特征的提取，与现有沙箱相结合，寻找可以优化现有检测方式
- 3）阅读关于逃逸分类器SP的相关论文 一 篇，以及详细阅读报告---Down

（Updated on 2018/2/12）
- 1)平衡正常样本数据集，目前收集到正常样本数据集达 万级别，恶意样本 十万级别
- 2)针对分类器逃逸的实验环境，已经搭建完成，整理数据集后，即可经常分类器逃逸实验，及分类器鲁棒性检测
- 3）阅读关于逃逸分类器SP的相关论文 一篇，以及详细阅读报告---Down

（Updated on 2018/1/10） 
- 1) 使用其他两个分类PDF分类器，以研究文件逃逸原理与实验模型的实现 -> In Progress  
- 2) 研读2017 深度特征的多平台的PDF论文，再对现有的分类器进行改善  
- 3）平衡正常样本数据集，现在增加200个，时间是1017年不等

（Updated on 2018/1/8）
- 1)注释每一个特征所对应的含义 -> Down
- 2)完善实验报告的内容和数据表的整理 -> Down
- 3）使用其他两个分类PDF分类器，以研究文件逃逸原理与实验模型的实现 -> In Progress

（Updated on 2017/12/18）
- 1） 使用MLlib 的编码思路，将每一步都做一个结果输出，如流水线方式以方便数据处理的多途径，多解决思路。在我们搭建的集群的NOTEBOOKS 运行使用以及测试，输出结果集，做实验总结
- 2）精度：精度与单机版测试差不多，均在99%，2.时间：数据处理量和运行时间就明显快很多，以下是预测函数的时间比：

----- 机版预测 200个 样本需要 10s 

----- Spark 上运行 2千多个 预测需要1.4s 

- 3）主要时间还是花在特征提取上，后续会把自己写的提取的脚本就开始慢慢的添加上去，替换第三方库，缩短文件提取时间



（Updated on 2017/12/11）
- 1）	数据集：

normal sample number  :  897

malware sample number  :  83442 

在做训练和推测的时候，随机抽取其中的部分做训练和测试做dataset 
- 2） 特征提取：
对提取到的特征做特征优化，目前按照参考论文，目前提取的特征有133个 ，以下是一些重要特征的分布图
![image](https://github.com/weijiang2009/Bluedon/blob/master/Industry/BluedonBigDataMachineLearingEngine/MalwarePDFDetection/featureim.png)
![image](https://github.com/weijiang2009/Bluedon/blob/master/Industry/BluedonBigDataMachineLearingEngine/MalwarePDFDetection/feature2.png)

- 3）模型识别率：
平均模型识别率均在 98.00% ，使用特征133个经过多次测试 
- 以下是在样本中随机抽取2300个样本做出的一个预测结果截图：模型识别能力达 >= 99.00%
![image](https://github.com/weijiang2009/Bluedon/blob/master/Industry/BluedonBigDataMachineLearingEngine/MalwarePDFDetection/solution2300.png)
- 如图是是在样本中随机抽取2355个样本做出的一个预测结果截图：模型识别能力达 >= 99.00%
![image](https://github.com/weijiang2009/Bluedon/blob/master/Industry/BluedonBigDataMachineLearingEngine/MalwarePDFDetection/solution2355.png)
- 4). 目前测试属于单机测试，正在逐步向Spark 大数据集群上转移，目前正在不断的测试中

（Updated on 2017/11/13）
- 1.充分利用现有数据，对提取到的特征做特征优化，目前按照参考论文，提取的又有特征有54个
- 2.增加对PDF文件解析的数量，主要主对FN/FT 文件进行优化和解析
- 3.参考国内外对PDF文件的解析，做实验原型的验证，目标提取有用特征200个,模型识别能力达 >= 98.00%

（Updated on 2017/10/30）
- 1. 充分利用现有数据，对提取到的特征做特征优化，优化后分析样本1000个，模型识别能力达 >= 97.00%
- 2. 增加对PDF文件解析的数量，由之前的各位提升到十位，争取破百位
- 3. 参考国内外对PDF文件的解析，做实验原型的验证，目标提取有用特征200个,更新之前的特征提取，现可用特征提取有37个

（Updated on 2017/10/11）
- 1.针对爬取到的数据，进行清理，分类出可用的做数据测试
- 2.增加可用测试样本到1000 ，提取样本特征143 个，模型识别能力达 >= 92.98%
- 3.针对特征提取和分析算法上的改进，参考国内外论文，做一步一步的实践

(Updated on 2017/09/29)
- 1.平衡PDF数据集样本，爬取测试样本到万 级，恶意样本 到十万 级
- 2.应用到机器学习框架来判断分析PDF文件，提取特征 143 个，分析样本500 个，模型识别能力达 >=91.89%
- 3.ing 深入分析PDF文件，不断恶意代码识别的优化及算法，参考国内外论文进行下一步深入分析

(Updated on 2017/08/28)
- 1.收集恶意PDF文件 156035 个（目前已经收集到 十万级）
- 2.基于ML技术框架，添加PDF特征提取和解析，完成一个完整的检测过程，输出检测结果
- 3.输出实验报告和结果分析，并不断优化迭代

Note: 目前对PDF的特征提取,主要是利用python内置包（如pdfminer）和导入开源包peepdf等，参考一些前沿技术文章对一下特征进行提取：

| Feature | Detail | Remarks |
| ------| ------ | ------ |
|the author metadata item 作者元数据项目|== producer_len ==| 
|the author metadata item 作者元数据项目| producer_oth | 
|the author metadata item 作者元数据项目| producer_uc | 
|objects/streams| ==len(objects)== | 
|objects/streams| ==数量(count)==  |
|objects/streams| location | 
|objects/streams| count_stream_diff | 
|objects/streams| len_stream_min | 
|images | len() | 
|images| location | 
|images| image_totalpx | 
|images| ratio_imagepx_size | 
|数据编码方法|==data encoding methods==|
|object types| ==计数加密对象（count of encryption objects）==|
|计数JavaScript|==len(objects)==|
| 计数JavaScript |==数量(count)==
|计数JavaScript|location
|计数js|==len(objects)==
|计数js|==数量(count)==
|计数js|location
|Font|==count_font==
|time|createdate_tz|
|time|moddate_tz
|object|==count_obj==
|object|count_endobj
||pdfid0_mismatch|
||pos_eof_avg|
||pos_eof_max|
|Boxes|pos_box_max|
||creator_len
||ref_min_id
||title_len
||title_lc
||count_filter_obs
||pos_ref_avg
|version|==version==
||==len_URLs==
||==openAction==



下一步:
增加测试数量集，优化特征提取，增加优化算法
- 1.用爬虫不断增加测试样本数量级，
- 2.深入分析PDF文件，不断恶意代码识别的优化及算法，参考国内外论文进行下一步深入分析

## Peer Code Review
(Updated on 2017/09/07 by Deyuan Li)
- 1.加深对PDF文件格式以及PDF病毒常见的文件特征的认识，可结合具体的文献资料，起步时可采用小数据集（理想化的数据）&简单特征
- 2.特征需要量化才能作为机器学习模型的输入，并且可通过统计分析的方法证明特征的有效性

## How to Compile / Run the code 
- ####Dependencies
-PyV8 (and V8) (optional: if you intend to use JS deobfuscation. Note: JS deobfuscation needs to be run in a safe environment, as you would treat any malware.
-lxml
-scandir (optional: module included in lib folder)
-postgresql and psycopg2 (optional: if you intend to use postgresql backing storage)
####Open Source PDF Tools

-peePDF
-PDFMiner
-swf mastah

####How does it work?
- How do you perform this tool to analyze if your PDF is malicious?
~The basic syntax is:

~~$ python peepdf.py pdf_file
   
 ~But you can use the -f option to avoid errors and to force the tool to ignore them:

~~$ python peepdf.py fcexploit.pdf

- Now you can get the following information

- MD5
- SHA1
- Catalog
- Objects with JS code
- Suspicious elements
- Size
- ...

## Python Project Structure
Q: Imagine that you want to develop a non-trivial end-user desktop (not web) application in Python.What is the best way to structure the project's folder hierarchy? Desirable features are ease of maintenance, IDE-friendliness, suitability for source control branching/merging, and easy generation of install packages. In particular:
  - Where do you put the source?
  - Where do you put application startup scripts?
  - Where do you put the IDE project cruft?
  - Where do you put the unit/acceptance tests?
  - Where do you put non-Python data such as config files?
  - Where do you put non-Python sources such as C++ for pyd/so binary extension modules?

A: Doesn't too much matter. Whatever makes you happy will work. There aren't a lot of silly rules because Python projects can be simple.
  - /scripts or /bin for that kind of command-line interface stuff
  - /tests for your tests
  - /lib for your C-language libraries
  - /doc for most documentation
  - /apidoc for the Epydoc-generated API docs

## Q&A
 - (This section should be answered by **Fengjiao**)

### Accuracy
  - Upon how much data does the machine learning solution base its decisions? Is it enough?

  - From where does the data come? Is there a wide variety of sources, or are they dependent on third-party threat aggregator sites?

  - How often is the data collected?

  - How often are new models trained and propagated to the customer?

  - How is the system trained? Is it trained through a constant supply of rich data sets, so properties discovered can be used in future machine learning decisions?

  - How does the vendor handle false positives?

  - How does the vendor handle false negatives that the vendor later discovers (after the customer has run the malware)?

### Speed
  - How quickly can the solution make a determination that leads to action?

  - How quickly can it obtain enough relevant new data to influence the decisions it makes?

### Efficiency
  - Where and how quickly does the analysis take place?

  - What is the impact on the end-user system?

  - What type of analysis is done on incoming files? On endpoints only, on cloud only, or a combination?

  - Does it rely on post-event analysis (detecting rather than preventing)?

## References
- [PlatPal: Detecting Malicious Documents with Platform Diversity USENIXSec 2017](https://www.dropbox.com/sh/5nwwv0algh2jpg6/AABadLuyfTWyB_-Lz6ZzAXdVa?dl=0)
